{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB12 - Explore NetworkX for course information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the SQL query below to get the relevent course/programme regulation data from our database. The data was then saved as a CSV file.\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM lse_doc\n",
    "WHERE url ILIKE '%courseGuides%'\n",
    "   OR url ILIKE '%programmeRegulations%';\n",
    "```\n",
    "\n",
    "This filters for urls that contain 'courseGuides' or 'programmeRegulations'. I chose these manually by browsing the lse calendar webpages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_FOLDER = os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', '..', 'data')\n",
    "#This should take about 1 minute\n",
    "df = pd.read_csv(\"/Users/jamie/Desktop/chatlse2024/chat-lse/data/data-1726582420261.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct the Graph using NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare Embeddings\n",
    "We must first convert the embeddings, currently type string, to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['embedding'][0]))\n",
    "print(len(df['embedding']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of testing, we use a small subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the 2000 rows from the middle of the dataframe\n",
    "df = df[54000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_embedding(embedding_str):\n",
    "    return np.array(ast.literal_eval(embedding_str))\n",
    "\n",
    "if isinstance(df['embedding'].iloc[0], str):\n",
    "    df['embedding_array'] = df['embedding'].apply(convert_embedding)\n",
    "else:\n",
    "    df['embedding_array'] = df['embedding']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Construct the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    G.add_node(idx, title=row['title'], url=row['url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Stack embeddings into a matrix\n",
    "embedding_matrix = np.vstack(df['embedding_array'].values)\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 0.8  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get indices where similarity is above the threshold (excluding self-similarity)\n",
    "indices = np.where((similarity_matrix > similarity_threshold) & (similarity_matrix < 0.99999))\n",
    "\n",
    "# Add edges to the graph\n",
    "for i, j in zip(indices[0], indices[1]):\n",
    "    G.add_edge(i, j, weight=similarity_matrix[i, j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain\n",
    "\n",
    "# Compute the best partition\n",
    "partition = community_louvain.best_partition(G, weight='weight')\n",
    "\n",
    "# Add community information to nodes\n",
    "nx.set_node_attributes(G, partition, 'community')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a dictionary to hold communities\n",
    "communities = defaultdict(list)\n",
    "for node, community_id in partition.items():\n",
    "    communities[community_id].append(node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Observe the Community Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for community_id, nodes in communities.items():\n",
    "    print(f\"Community {community_id}: {len(nodes)} nodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the community ID you want to inspect\n",
    "community_id_to_inspect = 841\n",
    "\n",
    "# Get the nodes in the community\n",
    "nodes_in_community = communities[community_id_to_inspect]\n",
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Extract corresponding data\n",
    "community_df = df.loc[nodes_in_community]\n",
    "\n",
    "# Display sample content\n",
    "print(community_df[['title', 'url']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-lse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
