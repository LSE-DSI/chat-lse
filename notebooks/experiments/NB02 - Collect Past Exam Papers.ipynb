{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJECTIVE:** Demonstrate that we can access data that is stored behind LSE's login page.\n",
    "\n",
    "**AUTHOR:** [Kristina Dixon](https://www.github.com/KristinaD1910) (edited by [@jonjoncardoso](https://github.com/jonjoncardoso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **SETUP**\n",
    "\n",
    "- Ensure you are running with the `chat-lse` conda environment and that you're up to date. See [README.md](../../README.md) if you haven't set up your environment yet.\n",
    "\n",
    "    On the command line:\n",
    "\n",
    "    ```bash\n",
    "    conda activate chat-lse\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "    <span style=\"color:red\">**Note:** Run the code above even if you have already configured your conda environment. Some packages might have changed.</span>\n",
    "\n",
    "- On VSCode, select `chat-lse` as the Python interpreter for this notebook and project.\n",
    "\n",
    "**üîê LSE Credentials**\n",
    "\n",
    "You will need to provide your LSE credentials for this.\n",
    "\n",
    "\n",
    "- If you haven't already, create a `.env` file in the root of this project. If it's your first time doing that, you can copy from the [`.env.sample` file](../../.env.sample). \n",
    "- Modify the variables `LSE_USERNAME` and `LSE_PASSWORD` so they contain your LSE credentials (e-mail and password, respectively)\n",
    "\n",
    "    For example:\n",
    "\n",
    "    ```bash\n",
    "    LSE_USERNAME=J.Cardoso-Silva@lse.ac.uk\n",
    "    LSE_PASSWORD=MySuperSecretPassword\n",
    "    ```\n",
    "- Have your Microsoft Authenticator app ready to approve the login request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import jsonlines\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "LSE_USERNAME = os.getenv('LSE_USERNAME')\n",
    "LSE_PASSWORD = os.getenv('LSE_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Util Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safely_get_elements(driver, css_selector, is_single_element=False, retries=3, wait_time=10):\n",
    "    \"\"\"\n",
    "    More than simply return the element(s) based on the given CSS selector, \n",
    "    this function ensures the elements are visible on the page before trying to capture them\n",
    "    and it also retries the operation a few times in case of failure.\n",
    "\n",
    "    A function generic enough that can be used by any of our future Selenium scripts.\n",
    "\n",
    "    Args:\n",
    "        driver (WebDriver): The Selenium WebDriver instance.\n",
    "        css_selector (str): The CSS selector to locate the elements.\n",
    "        is_single_element (bool): Flag indicating whether to retrieve a single element or multiple elements.\n",
    "        retries (int, optional): The number of retries in case of failure. Defaults to 3.\n",
    "        wait_time (int, optional): The maximum wait time for the elements to be located. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        WebElement or list: The located web element(s) based on the given CSS selector. \n",
    "        If `is_single_element` is True, a single WebElement is returned. If `is_single_element` is False, a list of WebElements is returned.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    elements = None  # Output variable\n",
    "\n",
    "    # Expected conditions\n",
    "    ec_single_element = EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "    ec_multiple_elements = EC.visibility_of_all_elements_located((By.CSS_SELECTOR, css_selector))\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            if is_single_element:\n",
    "                elements = WebDriverWait(driver, wait_time).until(ec_single_element)\n",
    "            else:\n",
    "                elements = WebDriverWait(driver, wait_time).until(ec_multiple_elements)\n",
    "            break\n",
    "        except (StaleElementReferenceException, TimeoutException) as e:\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Failed to get element{'s' if is_single_element else ''}: {e}\")\n",
    "                if is_single_element:\n",
    "                    return None\n",
    "                else:\n",
    "                    return []\n",
    "\n",
    "    return elements\n",
    "\n",
    "def safely_locate_element(driver, xpath, wait_time=5):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, wait_time).until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "        return element\n",
    "    except TimeoutException:\n",
    "        return None\n",
    "\n",
    "\n",
    "def safely_click_element(driver, xpath, must_click=False, wait_time=5):\n",
    "    \"\"\"\n",
    "    After ensuring that the element is visible on the page, clicks on it.\n",
    "\n",
    "    A function generic enough that can be used by any of our future Selenium scripts.\n",
    "\n",
    "    Args:\n",
    "        driver (WebDriver): The Selenium WebDriver instance.\n",
    "        xpath (str): The XPath to locate the element.\n",
    "        must_click (bool, optional): Flag indicating whether the element MUST be clicked. If it's a must, then a message is printed if the element cannot be clicked. Defaults to False.\n",
    "        wait_time (int, optional): The maximum wait time for the element to be clickable. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        None. It simply prints an error message if the element cannot be clicked.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        element = safely_locate_element(driver, xpath, wait_time=wait_time)\n",
    "        if element:\n",
    "            element.click()\n",
    "    except TimeoutException as e:\n",
    "        print(f\"Failed to click element: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logging in to LSE (via the LSE Library website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Firefox()\n",
    "driver.get('https://www.lse.ac.uk/library')\n",
    "\n",
    "# enter full screen\n",
    "driver.fullscreen_window()\n",
    "\n",
    "# Let the user actually see something!\n",
    "WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.ID, 'Loginto'))).click()\n",
    "\n",
    "# TODO: This part here could be moved to a `lse_login()` function to be reused in other scripts\n",
    "\n",
    "# Let the user actually see something!\n",
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[3]/div/div/h3[1]/a'))).click()\n",
    "\n",
    "# Let the user actually see something!\n",
    "WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.NAME, 'loginfmt'))).send_keys(LSE_USERNAME)\n",
    "\n",
    "# Let the user actually see something!\n",
    "next_button = WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.ID, 'idSIButton9')))\n",
    "if next_button:\n",
    "    next_button.click()\n",
    "else:\n",
    "    print(\"No next button found\")\n",
    "\n",
    "# Let the user actually see something!\n",
    "WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.NAME, 'passwd'))).send_keys(LSE_PASSWORD)\n",
    "\n",
    "# Let the user actually see something!\n",
    "next_button = WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.ID, 'idSIButton9')))\n",
    "next_button.click()\n",
    "\n",
    "#For the Microsoft Authenticator - number for user to enter into app.\n",
    "print(WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, '//*[@id=\"idRichContext_DisplaySign\"]'))).text)\n",
    "\n",
    "# Wait until the screen changes, this can be a variable length of time though\n",
    "try:\n",
    "    # Wait until the element is visible\n",
    "    element = WebDriverWait(driver, 300).until(EC.visibility_of_element_located((By.ID, 'idBtn_Back')))\n",
    "    # Act on the element as soon as it becomes visible\n",
    "    element.click()\n",
    "except TimeoutException:\n",
    "    print(\"The element did not appear within the time limit\")\n",
    "\n",
    "# Let the user actually see something!\n",
    "WebDriverWait(driver, 5).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div.grid-item:nth-child(1) > button:nth-child(1)'))).click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Demo of our custom Selenium functions\n",
    "\n",
    "**NOTE:** if you just want to run the full selenium code, skip to section 3 of this notebook.\n",
    " \n",
    "Now that we are logged in and on the library page, click on the 'Exam Papers' link to access the past exam papers and download them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go to the exam papers page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div[data-main-menu-item=\"ExamPapers\"] > a'))).click()\n",
    "\n",
    "# Move the driver to the page that lists all the exam papers per department\n",
    "# NOTE: This works fine, but be careful not to re-run this cell as it will be stuck in an infinite loop (due to the num_windows=2 condition)\n",
    "WebDriverWait(driver, 10).until(EC.number_of_windows_to_be(2))\n",
    "new_window = driver.window_handles[-1]\n",
    "driver.switch_to.window(new_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Replicability notes I: demonstration of the `get_elements()` function\n",
    "\n",
    "To whoever needs to copy and adapt from this template to parse other pages, here's a demonstration of how to use the `get_elements()` function to get the elements you need once the driver is on the page you want to parse.\n",
    "\n",
    "The CSS Selector below represents each one of the boxes shown in the sub-collections below:\n",
    "\n",
    "![image](https://github.com/latentnetworks/vimure/assets/896254/2a05478a-934b-43f0-92dc-7141bea85400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of department boxes collected: 25\n"
     ]
    }
   ],
   "source": [
    "driver.execute_script(\"document.body.style.zoom='30%'\")\n",
    "department_boxes = safely_get_elements(\n",
    "    driver=driver,\n",
    "    is_single_element=False, # Because we're collecting multiple divs set to False\n",
    "    css_selector=\".margin-bottom-small > prm-gallery-collection\",  # The CSS selector for the department boxes shown above\n",
    "    wait_time=60 # Increase the wait time to 60 seconds\n",
    ")\n",
    "# This should return 25 elements\n",
    "print(f\"Number of department boxes collected: {len(department_boxes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Replicability notes II: demonstration of the `safely_click_element()` function\n",
    "\n",
    "For this demonstration, let's click on the first box in the collection (Accounting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we run `curr_box.click()`, we will essentially be sending the driver to the following URL:\n",
      "https://librarysearch.lse.ac.uk/discovery/collectionDiscovery?vid=44LSE_INST%3A44LSE_VU1&collectionId=81235317140002021&lang=en\n"
     ]
    }
   ],
   "source": [
    "curr_box = department_boxes[0]\n",
    "\n",
    "title = curr_box.find_element(By.TAG_NAME, \"h3\").text\n",
    "subject_page_url = curr_box.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "\n",
    "print(f\"When we run `curr_box.click()`, we will essentially be sending the driver to the following URL:\\n{subject_page_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow the first box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_box.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, on this new page we see a list of PDFs. \n",
    "\n",
    "Here's how the `safely_locate_element()` and `safely_click_element()` functions can be used to click on the first exam papers in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDFs found: 17\n"
     ]
    }
   ],
   "source": [
    "containers = safely_get_elements(driver, f\".is-grid-view > prm-gallery-item\")\n",
    "print(f\"Number of PDFs found: {len(containers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we would be able to download the PDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Replicability notes III: demonstration of the `safely_locate_element()` function\n",
    "\n",
    "Some of the department pages contain multiple pages of past exam papers that are loaded dynamically. In these cases, we need to check if there is a 'Show More' button and then repeatedly click on it until we have all the exam papers loaded.\n",
    "\n",
    "The `safely_locate_element()` function can be used to check if the 'Show More' button is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back() # Go back to the previous page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the boxes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "department_boxes = safely_get_elements(\n",
    "    driver=driver,\n",
    "    is_single_element=False, # Because we're collecting multiple divs set to False\n",
    "    css_selector=\".margin-bottom-small > prm-gallery-collection\",  # The CSS selector for the department boxes shown above\n",
    "    wait_time=60 # Increase the wait time to 60 seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the 'Anthropology' page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_box = department_boxes[1] # I know that the second box leads to a page that matches the criteria above\n",
    "\n",
    "curr_box.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know for a fact that there is a 'Load more items' button at the bottom of the page. Let's use the `safely_locate_element()` function to confirm it's there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ed536899-14c1-4bde-a64d-eba1f2fc62ab\", element=\"b431c35b-1935-45ad-aaaa-f70a260bf5e9\")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of a highly specific absolute XPath, let's write a more generic one that can extract a <button> element with the text \"Load More items\"\n",
    "button_xpath = \"//button[contains(text(), 'Load more items')]\"\n",
    "\n",
    "# driver.find_element(By.XPATH, button_xpath)\n",
    "element = safely_locate_element(driver, button_xpath)\n",
    "element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a `WebElement` so it means the button is there. Now we can click on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "safely_click_element(driver, button_xpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would continue to do this until we have all the exam papers loaded.\n",
    "\n",
    "OK, enough with the demos of our custom functions. Let's go back to the main page and download the exam papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Collect exam papers from all departments\n",
    "\n",
    "Once we're logged in, we can collect the exam papers from all departments. Re-run the code in Section 1 if you need to log in again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Functions to collect exam papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once in a department page, collect metadata about the exam papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_department_exam_papers(driver, box_url, waiting_modifier=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Scrapes exam papers for a given department.\n",
    "\n",
    "    Args:\n",
    "        driver: The Selenium WebDriver instance.\n",
    "        department_box: The WebElement representing the department box.\n",
    "        waiting_modifier: A modifier to adjust the waiting time for element location and clicking. \n",
    "                          For example, when set to 2, if a function waits for 10 seconds, it will wait for 20 seconds instead. Defaults to 1.\n",
    "        verbose: A boolean indicating whether to print verbose output.\n",
    "\n",
    "    Returns:\n",
    "        A generator that yields a dictionary containing the scraped information for each exam paper.\n",
    "\n",
    "    \"\"\"\n",
    "    driver.get(box_url)\n",
    "\n",
    "    # Department nametitle\n",
    "    department_name = safely_locate_element(driver, \"//h1[contains(@class, 'collection-title')]\", wait_time=waiting_modifier*10).text\n",
    "    print(f\"Scraping exam papers for department: {department_name}\")\n",
    "    \n",
    "    # URL with listings of exam papers for this department\n",
    "    department_listing_url = box_url\n",
    "    \n",
    "    # Click load more button repeatedly until all exam papers are loaded\n",
    "    if verbose:\n",
    "        print(\"Loading all exam papers...\")\n",
    "    load_more_button_selector = \"//button[contains(text(), 'Load more items')]\"\n",
    "    while safely_locate_element(driver, load_more_button_selector, wait_time=waiting_modifier*3):\n",
    "        safely_click_element(driver, load_more_button_selector, wait_time=waiting_modifier*3)\n",
    "\n",
    "    # Retrieve the total number of PDFs in this listing\n",
    "    if verbose:\n",
    "        print(\"Counting the number of exam papers...\")\n",
    "    marker_num_items = 'Items in this collection'\n",
    "    xpath_num_items = f\"//h2[./span[contains(text(), '{marker_num_items}')]]\"\n",
    "    count_pdfs = safely_locate_element(driver, xpath_num_items, wait_time=waiting_modifier*10).text\n",
    "    count_pdfs = int(\n",
    "        count_pdfs.split(marker_num_items)[1]\n",
    "        .strip()\n",
    "        .replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Number of exam papers found: {count_pdfs}. Looping through each...\")\n",
    "    for i in trange(count_pdfs):\n",
    "        if verbose:\n",
    "            print(f\"Scraping exam paper {i+1} of {count_pdfs}...\")\n",
    "        containers = safely_get_elements(driver, f\".is-grid-view > prm-gallery-item\", wait_time=waiting_modifier*0)\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", containers[i])\n",
    "        container = containers[i]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Clicking on the exam paper...\")\n",
    "        driver.execute_script(\"document.body.style.zoom='30%'\")\n",
    "        course_name = container.find_element(By.CLASS_NAME, \"item-title\").text\n",
    "        # FIXME: Find a more human-readable CSS selector for the type\n",
    "        type = container.find_element(By.CSS_SELECTOR, \"div:nth-child(2) > div:nth-child(2) > span:nth-child(1) > span:nth-child(1)\").text\n",
    "\n",
    "        driver.execute_script(\"window.scrollBy(0, -200);\")  # Scroll up by 200 pixels \n",
    "        \n",
    "        container.click()\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Checking for 'Show More' button...\")\n",
    "        #FIXME: Find a more human-readable XPath for the 'Show More' button\n",
    "        show_more_selector = \"/html/body/primo-explore/div[3]/div/md-dialog/md-dialog-content/sticky-scroll/prm-full-view/div/div/div/div/div[1]/div[4]/div/prm-full-view-service-container/div[2]/div/prm-alma-viewit/prm-alma-viewit-items/button\"\n",
    "        if safely_click_element(driver, show_more_selector, wait_time=waiting_modifier*5):\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"'Show More' button not visible. Continuing...\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Scraping exam paper details...\")\n",
    "        exams = safely_get_elements(driver, \"md-list-item.md-3-line\", wait_time=waiting_modifier*5)\n",
    "\n",
    "        #scroll to top of page - this could be the key to resolving the issue of 'Failed to get elements'\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Scrolling to the top of the page...\")\n",
    "        # FIXME: Define a more human-readable CSS selector for the element to scroll to\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", driver.find_element(By.CSS_SELECTOR,'#action_list > div:nth-child(1) > prm-full-view-service-container:nth-child(1) > div:nth-child(1) > prm-service-header:nth-child(1)'))\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Extracting metadata about each year's exam paper...\")\n",
    "        for n in range(1, len(exams) + 1):\n",
    "            #FIXME: Find a more human-readable CSS selector for the exam paper\n",
    "            css_selector = f\"md-list-item.md-3-line:nth-child({n}) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > a:nth-child(1)\"\n",
    "            exam = safely_get_elements(driver, css_selector, is_single_element=True, wait_time=waiting_modifier*0)\n",
    "\n",
    "            if exam:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", exam)\n",
    "                exam_year = exam.text\n",
    "                pdf_link = exam.get_attribute(\"href\")\n",
    "\n",
    "                yield {\n",
    "                    \"department_name\": department_name,\n",
    "                    \"department_listing_url\": department_listing_url,\n",
    "                    \"course_name\": course_name,\n",
    "                    \"type\": type,\n",
    "                    \"exam_year\": exam_year,\n",
    "                    \"pdf_link\": pdf_link,\n",
    "                }\n",
    "\n",
    "        exit_button = safely_get_elements(driver, \"button.md-icon-button:nth-child(4)\", is_single_element=True, wait_time=waiting_modifier*5)\n",
    "        if exit_button:\n",
    "            exit_button.click()\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            print(\"Exit button not found. Returning\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the exam papers for all departments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_URL = \"https://librarysearch.lse.ac.uk/discovery/collectionDiscovery?vid=44LSE_INST:44LSE_VU1&collectionId=81235317150002021&lang=en\"\n",
    "SUPER_JSONL_FILE = \"../../data/lse_exam_papers.jsonl\"\n",
    "CHECKPOINT_FILE = \"../../data/lse_exam_papers_checkpoint.txt\"\n",
    "\n",
    "def scrape_all_departments(driver, \n",
    "                           collection_url=COLLECTION_URL, \n",
    "                           jsonl_file=SUPER_JSONL_FILE,\n",
    "                           checkpoint_file=CHECKPOINT_FILE,\n",
    "                           waiting_modifier=1, \n",
    "                           verbose=False):\n",
    "    \"\"\"\n",
    "    Scrapes past exam papers looping through all departments and writing the data to a JSONL file.\n",
    "    The code is designed to be robust and can be re-run without losing data.\n",
    "    The checkpoint file is used to keep track of which URLs have already been scraped so that they are not scraped again.\n",
    "    Only once all URLs of a given department have been scraped will the code move on to the next department.\n",
    "    If the checkpoint file is not found, it will be created.\n",
    "    When restarting the code, past papers from partially scraped departments might still be captured again, so\n",
    "    it's recommended to remove duplicates from the JSONL file after scraping is complete.\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_json(\"data/lse_exam_papers.jsonl\", lines=True).drop_duplicates()\n",
    "    ```\n",
    "\n",
    "    Args:\n",
    "        driver (WebDriver): The Selenium WebDriver instance used for web scraping.\n",
    "        collection_url (str): The URL of the collection page containing department boxes.\n",
    "        jsonl_file (str): The path to the JSONL file where the scraped data will be stored.\n",
    "        checkpoint_file (str): The path to the checkpoint file used to track scraped URLs.\n",
    "        waiting_modifier (int): A modifier to adjust the waiting time for page elements to load.\n",
    "        verbose (bool): If True, additional information will be printed during the scraping process.\n",
    "\n",
    "    Returns:\n",
    "        None. This is a side-effect only function that writes data to a JSONL file.\n",
    "    \"\"\"\n",
    "    \n",
    "    driver.get(collection_url)\n",
    "    driver.execute_script(\"document.body.style.zoom='30%'\")\n",
    "\n",
    "    # Scroll to the bottom of the page to load all department boxes\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(10*waiting_modifier)\n",
    "\n",
    "    department_boxes = safely_get_elements(\n",
    "        driver=driver,\n",
    "        css_selector=\".margin-bottom-small > prm-gallery-collection\",\n",
    "        wait_time=60,  # Increase the wait time to 60 seconds to ensure all department boxes are loaded\n",
    "    )\n",
    "    boxes_urls = [box.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\") for box in department_boxes]\n",
    "    if verbose:\n",
    "        print(f\"Number of department boxes to scrape: {len(department_boxes)}\")\n",
    "\n",
    "    # Read checkpoint file to determine which URLs have already been scraped\n",
    "    if not os.path.exists(checkpoint_file):\n",
    "        open(checkpoint_file, 'w').close() # https://stackoverflow.com/a/61164327/843365\n",
    "    with open(checkpoint_file, \"r\") as f:\n",
    "        scraped_urls = set(f.read().split(\"\\n\"))\n",
    "        try:\n",
    "            scraped_urls.remove(\"\") # Remove the last empty line\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    if scraped_urls:\n",
    "        if verbose:\n",
    "            print(f\"Skipping {len(scraped_urls)} URLs that have already been scraped...\")\n",
    "            print(\"\\n\".join(scraped_urls))\n",
    "        boxes_urls = [url for url in boxes_urls if url not in scraped_urls]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Number of department boxes collected: {len(department_boxes)}\")\n",
    "        print(f\"Number of department boxes left to scrape: {len(boxes_urls)}\")\n",
    "\n",
    "    for box_url in boxes_urls:\n",
    "        exam_papers_listing = scrape_department_exam_papers(\n",
    "                driver,\n",
    "                box_url,\n",
    "                waiting_modifier=waiting_modifier,\n",
    "                verbose=verbose,\n",
    "            )\n",
    "        with jsonlines.open(jsonl_file, 'a') as writer:\n",
    "            print(f\"Writing most recent exam papers data to {jsonl_file}...\")\n",
    "            writer.write_all(exam_papers_listing)\n",
    "        with open(checkpoint_file, \"a\") as f:\n",
    "            f.writelines(f\"{box_url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run the scraper\n",
    "\n",
    "Tip: increase the `waiting_modifier` to make the scraper wait longer for the page to load. This is useful if you have a slow internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of department boxes to scrape: 25\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/lse_exam_papers_checkpoint.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scrape_all_departments(driver, waiting_modifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 54\u001b[0m, in \u001b[0;36mscrape_all_departments\u001b[0;34m(driver, collection_url, jsonl_file, checkpoint_file, waiting_modifier, verbose)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Read checkpoint file to determine which URLs have already been scraped\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_file):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28mopen\u001b[39m(checkpoint_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mclose() \u001b[38;5;66;03m# https://stackoverflow.com/a/61164327/843365\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(checkpoint_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     56\u001b[0m     scraped_urls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/chat-lse/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/lse_exam_papers_checkpoint.txt'"
     ]
    }
   ],
   "source": [
    "scrape_all_departments(driver, waiting_modifier=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Check that the JSONL file was created correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department_name\n",
       "Economic History    182\n",
       "Anthropology        139\n",
       "Accounting           59\n",
       "Economics            21\n",
       "Law                   7\n",
       "Data Science          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(SUPER_JSONL_FILE, lines=True).drop_duplicates()\n",
    "\n",
    "df['department_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACKING TODOs:**\n",
    "\n",
    "(Done with the refactoring)\n",
    "\n",
    "- [x] Test that Department of Law is working with the new version of the code\n",
    "- [x] Reintroduce the retry mechanism to the scraping functions\n",
    "- [ ] ~~Finish refactoring: add the missing 'Back' button functionality~~ (not needed any more)\n",
    "- [x] Finish refactoring: allow scraper to continue from where it left off if it crashes\n",
    "- [x] Finish refactoring: send output to a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
