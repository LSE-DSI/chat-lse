{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Defining nodes and relationships, uploading data to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 1066\n",
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 1070\n",
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 1086\n",
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 1317\n",
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 1318\n",
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 1330\n",
      "Created bidirectional SIMILAR relationship between chunk 1041 and chunk 2506\n",
      "Created bidirectional SIMILAR relationship between chunk 1066 and chunk 1070\n",
      "Created bidirectional SIMILAR relationship between chunk 1066 and chunk 1086\n",
      "Created bidirectional SIMILAR relationship between chunk 1066 and chunk 1317\n",
      "Created bidirectional SIMILAR relationship between chunk 1066 and chunk 1318\n",
      "Created bidirectional SIMILAR relationship between chunk 1066 and chunk 1330\n",
      "Created bidirectional SIMILAR relationship between chunk 1066 and chunk 2506\n",
      "Created bidirectional SIMILAR relationship between chunk 1070 and chunk 1086\n",
      "Created bidirectional SIMILAR relationship between chunk 1070 and chunk 1317\n",
      "Created bidirectional SIMILAR relationship between chunk 1070 and chunk 1318\n",
      "Created bidirectional SIMILAR relationship between chunk 1070 and chunk 1330\n",
      "Created bidirectional SIMILAR relationship between chunk 1070 and chunk 2506\n",
      "Created bidirectional SIMILAR relationship between chunk 34 and chunk 35\n",
      "Created bidirectional SIMILAR relationship between chunk 1086 and chunk 1317\n",
      "Created bidirectional SIMILAR relationship between chunk 1086 and chunk 1318\n",
      "Created bidirectional SIMILAR relationship between chunk 1086 and chunk 1330\n",
      "Created bidirectional SIMILAR relationship between chunk 1086 and chunk 2506\n",
      "Created bidirectional SIMILAR relationship between chunk 1317 and chunk 1318\n",
      "Created bidirectional SIMILAR relationship between chunk 1317 and chunk 1330\n",
      "Created bidirectional SIMILAR relationship between chunk 1317 and chunk 2506\n",
      "Created bidirectional SIMILAR relationship between chunk 1318 and chunk 1330\n",
      "Created bidirectional SIMILAR relationship between chunk 1318 and chunk 2506\n",
      "Created bidirectional SIMILAR relationship between chunk 1330 and chunk 2506\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import psycopg2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Neo4j connection details\n",
    "NEO4J_URI = 'neo4j+s://6d4b3e42.databases.neo4j.io'\n",
    "NEO4J_USERNAME = 'neo4j'\n",
    "NEO4J_PASSWORD = 'kS_bNoHQBucK1ab5Rb_UP8KNiTvooRfpXX_zvAQRKX0'\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "DB_HOST = \"158.143.74.10\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"chatlse\"\n",
    "DB_USER = \"chatlse\"\n",
    "DB_PASSWORD = 'chatlse'\n",
    "\n",
    "# Function to parse embedding strings\n",
    "def parse_embedding(embedding_str):\n",
    "    \"\"\"\n",
    "    Parse embedding string into a NumPy array.\n",
    "    Handles common formats like \"[0.1, 0.2, 0.3]\" or \"0.1, 0.2, 0.3\".\n",
    "    \"\"\"\n",
    "    if embedding_str is None or embedding_str.strip() == \"\":\n",
    "        return np.zeros(1024)  # Default zero vector for missing or empty embeddings\n",
    "\n",
    "    try:\n",
    "        # Remove brackets if present and convert to list\n",
    "        embedding_list = ast.literal_eval(embedding_str.strip()) if \"[\" in embedding_str else list(map(float, embedding_str.split(\",\")))\n",
    "        return np.array(embedding_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse embedding: {embedding_str}. Error: {e}\")\n",
    "        return np.zeros(1024)  # Default zero vector for invalid embeddings\n",
    "\n",
    "# Neo4j database class\n",
    "class Neo4jDatabase:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def create_chunk_node(self, doc_id, chunk_id, title, url, content, context_embedding, chunk_type):\n",
    "        query = \"\"\"\n",
    "        MERGE (c:Chunk {\n",
    "            doc_id: $doc_id,\n",
    "            chunk_id: $chunk_id\n",
    "        })\n",
    "        SET c.type = $chunk_type,\n",
    "            c.title = $title,\n",
    "            c.url = $url,\n",
    "            c.content = $content,\n",
    "            c.context_embedding = $context_embedding\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\n",
    "                query,\n",
    "                chunk_type=chunk_type,\n",
    "                doc_id=doc_id,\n",
    "                chunk_id=chunk_id,\n",
    "                title=title,\n",
    "                url=url,\n",
    "                content=content,\n",
    "                context_embedding=context_embedding,\n",
    "            )\n",
    "\n",
    "    def create_summary_chunk_node(self, doc_id, content, summary):\n",
    "        query = \"\"\"\n",
    "        MERGE (sc:SummaryChunk {\n",
    "            doc_id: $doc_id\n",
    "        })\n",
    "        SET sc.content = $content,\n",
    "            sc.summary = $summary,\n",
    "            sc.type = \"summary_chunk\"\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\n",
    "                query,\n",
    "                doc_id=doc_id,\n",
    "                content=content,\n",
    "                summary=summary,\n",
    "            )\n",
    "\n",
    "    def create_similar_relationship(self, doc_id1, chunk_id1, doc_id2, chunk_id2):\n",
    "        \"\"\"\n",
    "        Create a bidirectional SIMILAR relationship between two chunks.\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH (c1:Chunk {doc_id: $doc_id1, chunk_id: $chunk_id1}),\n",
    "            (c2:Chunk {doc_id: $doc_id2, chunk_id: $chunk_id2})\n",
    "        CREATE (c1)-[:SIMILAR]->(c2),\n",
    "            (c2)-[:SIMILAR]->(c1)\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, doc_id1=doc_id1, chunk_id1=chunk_id1, doc_id2=doc_id2, chunk_id2=chunk_id2)\n",
    "\n",
    "\n",
    "    def create_belongs_to_relationship(self, doc_id, chunk_id):\n",
    "        query = \"\"\"\n",
    "        MATCH (chunk:Chunk {doc_id: $doc_id, chunk_id: $chunk_id}),\n",
    "              (summary:SummaryChunk {doc_id: $doc_id})\n",
    "        CREATE (chunk)-[:BELONGS_TO]->(summary)\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, doc_id=doc_id, chunk_id=chunk_id)\n",
    "\n",
    "    def create_next_relationship(self, doc_id, prev_chunk_id, chunk_id):\n",
    "        query = \"\"\"\n",
    "        MATCH (prev:Chunk {doc_id: $doc_id, chunk_id: $prev_chunk_id}),\n",
    "              (current:Chunk {doc_id: $doc_id, chunk_id: $chunk_id})\n",
    "        CREATE (prev)-[:NEXT]->(current)\n",
    "        \"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.run(query, doc_id=doc_id, prev_chunk_id=prev_chunk_id, chunk_id=chunk_id)\n",
    "\n",
    "# Fetch and Create Nodes\n",
    "def fetch_and_create_nodes(db):\n",
    "    \"\"\"\n",
    "    Fetch chunks and summary chunks from PostgreSQL and create corresponding nodes in Neo4j.\n",
    "    Limits: 1000 chunks, 500 summary chunks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Fetch limited chunk data\n",
    "        chunks_query = \"\"\"\n",
    "        SELECT \n",
    "            doc_id, \n",
    "            chunk_id, \n",
    "            url, \n",
    "            title, \n",
    "            content, \n",
    "            context_embeddings \n",
    "        FROM lse_doc\n",
    "        LIMIT 1000;\n",
    "        \"\"\"\n",
    "        cursor.execute(chunks_query)\n",
    "        chunks = cursor.fetchall()\n",
    "\n",
    "        # Create Chunk nodes\n",
    "        for row in chunks:\n",
    "            doc_id, chunk_id, url, title, content, context_embeddings = row\n",
    "\n",
    "            # Parse embedding string into a vector\n",
    "            context_embedding = parse_embedding(context_embeddings)\n",
    "\n",
    "            db.create_chunk_node(\n",
    "                doc_id=doc_id,\n",
    "                chunk_id=chunk_id,\n",
    "                title=title,\n",
    "                url=url,\n",
    "                content=content,\n",
    "                context_embedding=context_embedding.tolist(),\n",
    "                chunk_type=\"chunk\"\n",
    "            )\n",
    "\n",
    "        # Fetch limited summary chunk data\n",
    "        summary_query = \"\"\"\n",
    "        SELECT \n",
    "            doc_id, \n",
    "            content, \n",
    "            summary \n",
    "        FROM doc_summary\n",
    "        LIMIT 500;\n",
    "        \"\"\"\n",
    "        cursor.execute(summary_query)\n",
    "        summaries = cursor.fetchall()\n",
    "\n",
    "        # Create SummaryChunk nodes\n",
    "        for row in summaries:\n",
    "            doc_id, content, summary = row\n",
    "            db.create_summary_chunk_node(\n",
    "                doc_id=doc_id,\n",
    "                content=content,\n",
    "                summary=summary\n",
    "            )\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    finally:\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "\n",
    "# Relationships\n",
    "def create_similar_relationships(db, chunks):\n",
    "    \"\"\"\n",
    "    Create SIMILAR relationships between chunks based on cosine similarity.\n",
    "    Ensures bidirectional relationships.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    doc_ids = []\n",
    "    chunk_ids = []\n",
    "\n",
    "    # Collect embeddings and chunk information\n",
    "    for chunk in chunks:\n",
    "        context_embedding = parse_embedding(chunk[5])  # Ensure parsing\n",
    "        if np.any(context_embedding):  # Exclude zero vectors\n",
    "            embeddings.append(context_embedding)\n",
    "            doc_ids.append(chunk[0])\n",
    "            chunk_ids.append(chunk[1])\n",
    "\n",
    "    if not embeddings:\n",
    "        print(\"No valid embeddings found for SIMILAR relationships.\")\n",
    "        return\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    threshold = 0.999\n",
    "\n",
    "    for i in range(len(doc_ids)):\n",
    "        for j in range(i + 1, len(doc_ids)):\n",
    "            if similarity_matrix[i][j] > threshold:\n",
    "                db.create_similar_relationship(\n",
    "                    doc_id1=doc_ids[i],\n",
    "                    chunk_id1=chunk_ids[i],\n",
    "                    doc_id2=doc_ids[j],\n",
    "                    chunk_id2=chunk_ids[j],\n",
    "                )\n",
    "                print(f\"Created bidirectional SIMILAR relationship between chunk {chunk_ids[i]} and chunk {chunk_ids[j]}\")\n",
    "\n",
    "\n",
    "def create_belongs_to_relationships(db, chunks):\n",
    "    for chunk in chunks:\n",
    "        doc_id = chunk[0]\n",
    "        chunk_id = chunk[1]\n",
    "        db.create_belongs_to_relationship(doc_id, chunk_id)\n",
    "\n",
    "def create_next_relationships(db, chunks):\n",
    "    doc_chunk_map = {}\n",
    "    for chunk in chunks:\n",
    "        doc_id = chunk[0]\n",
    "        chunk_id = chunk[1]\n",
    "        if doc_id not in doc_chunk_map:\n",
    "            doc_chunk_map[doc_id] = []\n",
    "        doc_chunk_map[doc_id].append(chunk_id)\n",
    "\n",
    "    for doc_id, chunk_ids in doc_chunk_map.items():\n",
    "        sorted_chunk_ids = sorted(chunk_ids)\n",
    "        prev_chunk_id = None\n",
    "        for chunk_id in sorted_chunk_ids:\n",
    "            if prev_chunk_id:\n",
    "                db.create_next_relationship(doc_id, prev_chunk_id, chunk_id)\n",
    "            prev_chunk_id = chunk_id\n",
    "\n",
    "# Main Script\n",
    "db = Neo4jDatabase(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "chunks = fetch_and_create_nodes(db)\n",
    "create_similar_relationships(db, chunks)\n",
    "create_belongs_to_relationships(db, chunks)\n",
    "create_next_relationships(db, chunks)\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fetching and Ingesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_id: d9b560cd04403aaacd6eb5d41ff7346d, chunk_id: 6, title: WP181.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 31, title: SchoolRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1262, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1264, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 6771adab6303462bc5a97d35b8c1363c, chunk_id: 1, title: Psychology of Inequality\n",
      "doc_id: 44883cb3eed83c297fe3eb73fad20568, chunk_id: 1, title: People, Work and Organisations\n",
      "doc_id: 3806bc2aa3dbc067a71b050472cec337, chunk_id: 0, title: The LSE Estate\n",
      "doc_id: 37a51a7bc7bee0978d5a477744cc5eb1, chunk_id: 3, title: I'm feeling suicidal or need emergency help\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1267, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1268, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: d9b560cd04403aaacd6eb5d41ff7346d, chunk_id: 30, title: WP181.pdf\n",
      "doc_id: 3806bc2aa3dbc067a71b050472cec337, chunk_id: 9, title: The LSE Estate\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1272, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 0942c01e158a7d6630914f2aa804b1b9, chunk_id: 8, title: Sustainable investment is good macroeconomics and fiscally prudent for the UK - Grantham Research Institute on climate change and the environment\n",
      "doc_id: 44883cb3eed83c297fe3eb73fad20568, chunk_id: 2, title: People, Work and Organisations\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1271, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 72, title: SchoolRegs16-17.pdf\n",
      "doc_id: 8e137b71ec29f99e333b3088549ace6f, chunk_id: 0, title: Student Records Team\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1275, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 36, title: WP158.pdf\n",
      "doc_id: d7c2bc87103cc11083458c2afbd0c0b6, chunk_id: 0, title: The Admissions process\n",
      "doc_id: ffdb1303e620c76b2314476e747c1e5c, chunk_id: 1, title: CSB-Rules-07-July-2017.pdf\n",
      "doc_id: f45aa40489814852e820edb5c1c22294, chunk_id: 0, title: How to request a room\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1281, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 8ef9ee0c26275964f23e3c41eb825be4, chunk_id: 0, title: Graduating from LSE\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1280, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 43, title: WP158.pdf\n",
      "doc_id: 6ef13c563ff84b39ac99e44a2dadd43d, chunk_id: 29, title: WP141.pdf\n",
      "doc_id: aab4b11989f2dcd01ace3e438be1eac7, chunk_id: 19, title: StuAccomDiscCo.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 54, title: WP158.pdf\n",
      "doc_id: 6ef13c563ff84b39ac99e44a2dadd43d, chunk_id: 33, title: WP141.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1285, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 205f27c58d521bedbb98964f1faa4fc1, chunk_id: 53, title: WP157.pdf\n",
      "doc_id: f6e9d903929f1b66351d768cc3feb592, chunk_id: 105, title: SchoolRegs12-13.pdf\n",
      "doc_id: 43fd932a014f54206d0d1453ce265fa2, chunk_id: 2, title: Organising events\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1291, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 65, title: WP158.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1289, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 6ef13c563ff84b39ac99e44a2dadd43d, chunk_id: 46, title: WP141.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1294, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1295, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: a1dce1f117a2c8e71c5d953b58edc5c6, chunk_id: 187, title: CourseGuidesProgrammeRegs15-16.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 137, title: SchoolRegs16-17.pdf\n",
      "doc_id: 6ef13c563ff84b39ac99e44a2dadd43d, chunk_id: 64, title: WP141.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1299, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: a1dce1f117a2c8e71c5d953b58edc5c6, chunk_id: 350, title: CourseGuidesProgrammeRegs15-16.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1298, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 186649802444e353d3f368207cd0236d, chunk_id: 0, title: ï»¿Research\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 177, title: SchoolRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1303, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 9d54f598c6e960a2385ac01c01170193, chunk_id: 9, title: WP180.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1301, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1302, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 76, title: WP158.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 202, title: SchoolRegs16-17.pdf\n",
      "doc_id: b8087423eb3738ba8e6b2e8d726b16fc, chunk_id: 2, title: A strategy for restoring confidence and economic growth through green investment and innovation - Grantham Research Institute on climate change and the environment\n",
      "doc_id: 82a6cf4833fcbf7ef4a43f4b44cfeb8e, chunk_id: 19, title: WP125.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1308, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 87, title: WP158.pdf\n",
      "doc_id: bcb547698e1ea712abca5685164ab775, chunk_id: 0, title: Crisis and Conflict\n",
      "doc_id: 0f535eb82734440a50f5697508aaca77, chunk_id: 1, title: A Country Divided? Polarisation and Identity After Brexit\n",
      "doc_id: 722c914fe40bcfc253c95e728cb81535, chunk_id: 6, title: Challenging Results\n",
      "doc_id: 47d2d379a8dfd043ce203f58c0405f2b, chunk_id: 175, title: WP226.pdf\n",
      "doc_id: bcb547698e1ea712abca5685164ab775, chunk_id: 4, title: Crisis and Conflict\n",
      "doc_id: 82a6cf4833fcbf7ef4a43f4b44cfeb8e, chunk_id: 22, title: WP125.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1316, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1314, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1315, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 222, title: SchoolRegs16-17.pdf\n",
      "doc_id: d751208b42dba2823bfc54ad34b5c527, chunk_id: 0, title: Applying for a Student Visa for a full time programme at LSE\n",
      "doc_id: 82a6cf4833fcbf7ef4a43f4b44cfeb8e, chunk_id: 33, title: WP125.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1318, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1319, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 2852450364953536c824dbb91166f560, chunk_id: 1, title: Social studies curriculum in Sub-Saharan Africa\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 148, title: WP158.pdf\n",
      "doc_id: d751208b42dba2823bfc54ad34b5c527, chunk_id: 3, title: Applying for a Student Visa for a full time programme at LSE\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1324, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 143, title: WP158.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 260, title: SchoolRegs16-17.pdf\n",
      "doc_id: db5b5996de5f35538fa5646904bc94b4, chunk_id: 0, title: Visiting Appointments\n",
      "doc_id: 3766ab5751c1300f7a0d7b79a14da016, chunk_id: 3, title: Global trends in climate change litigation: 2023 snapshot - Grantham Research Institute on climate change and the environment\n",
      "doc_id: 54f6e26efa56933f91df32d4a8e1562d, chunk_id: 2, title: temTecSol.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1327, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: d671ae27d272287f6b0985067bfb1613, chunk_id: 26, title: WP165-.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 290, title: SchoolRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1431, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 758dd0cf47f15063615e866097d8c175, chunk_id: 5, title: Conditional offer\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1344, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 298, title: SchoolRegs16-17.pdf\n",
      "doc_id: 9308f7367f6e20a51b72df9c5f386c0d, chunk_id: 3, title: Wellbeing\n",
      "doc_id: ccf2f6ec8fdcfabfad91718a3cb268a6, chunk_id: 1, title: Measuring wealth, delivering prosperity - Grantham Research Institute on climate change and the environment\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1466, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 985bda7268a8a552606806fba3afcae1, chunk_id: 164, title: WP158.pdf\n",
      "doc_id: cb8c6fe35af21ca7adb6c675118e9ac1, chunk_id: 474, title: CourseGuidesProgrammeRegs20-21.pdf\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 310, title: SchoolRegs16-17.pdf\n",
      "doc_id: 531e664e4c4bf513b6e22a934f5c69f7, chunk_id: 6, title: guiTraSta.pdf\n",
      "doc_id: 9308f7367f6e20a51b72df9c5f386c0d, chunk_id: 7, title: Wellbeing\n",
      "doc_id: 8bacaf3a836e796fb58e10aaa0782caf, chunk_id: 320, title: SchoolRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1357, title: CourseGuidesProgrammeRegs16-17.pdf\n",
      "doc_id: 420078fcb070239243f589fff414085a, chunk_id: 1355, title: CourseGuidesProgrammeRegs16-17.pdf\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# PostgreSQL connection parameters\n",
    "DB_HOST = \"158.143.74.10\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"chatlse\"\n",
    "DB_USER = \"chatlse\"\n",
    "DB_PASSWORD = \"chatlse\"\n",
    "\n",
    "def extract_chunk_ids(limit=50):\n",
    "    try:\n",
    "\n",
    "        connection = psycopg2.connect(\n",
    "            host=DB_HOST,\n",
    "            port=DB_PORT,\n",
    "            database=DB_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "\n",
    "        chunks_query = f\"\"\"\n",
    "        SELECT \n",
    "            doc_id, \n",
    "            chunk_id, \n",
    "            title \n",
    "        FROM lse_doc\n",
    "        LIMIT {limit};\n",
    "        \"\"\"\n",
    "        cursor.execute(chunks_query)\n",
    "        chunks = cursor.fetchall()\n",
    "\n",
    "        for chunk in chunks:\n",
    "            doc_id, chunk_id, title = chunk\n",
    "            print(f\"doc_id: {doc_id}, chunk_id: {chunk_id}, title: {title}\")\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    finally:\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "\n",
    "chunks = extract_chunk_ids(limit=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-lse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
